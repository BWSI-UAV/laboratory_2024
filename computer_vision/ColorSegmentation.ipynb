{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import ganymede\n",
    "ganymede.configure('uav.beaver.works')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ganymede.name('YOUR NAME HERE')\n",
    "def check(p): pass\n",
    "check(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopsigns = glob.glob(\"stopsigns/*.jpg\")\n",
    "stopsigns = [cv2.imread(s, cv2.IMREAD_COLOR) for s in stopsigns]\n",
    "print( \"{} stop signs in dataset\".format(len(stopsigns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "We have opened these images using OpenCV. What color format are these images in? BGR or RGB?\n",
    "\n",
    "https://docs.opencv.org/3.4.1/d3/df2/tutorial_py_basic_ops.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(stopsigns[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = stopsigns[0]\n",
    "b, g, r = cv2.split(s)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3, nrows=2)\n",
    "[a.axis('off') for a in ax.flatten()]\n",
    "ax[0,0].imshow(b, cmap='Blues')\n",
    "ax[0,1].imshow(g, cmap='Greens')\n",
    "ax[0,2].imshow(r, cmap='Reds')\n",
    "ax[1,0].imshow(b, cmap='gray')\n",
    "ax[1,1].imshow(g, cmap='gray')\n",
    "ax[1,2].imshow(r, cmap='gray')\n",
    "fig.set_size_inches(15,7);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Convert the first stop sign image from BGR to RGB (`cv2.cvtColor(YOUR_IMAGE, cv2.COLOR_BGR2RGB)`), to HSV, and to LAB. \n",
    "\n",
    "For each colorspace, visualize the three channels (you probably want to use the gray colormap to compare between the three color spaces).\n",
    "\n",
    "Which colorspace isolates the stop sign the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A dataset of stop sign images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=len(stopsigns))\n",
    "for (a,s) in zip(ax,stopsigns):\n",
    "    a.imshow(cv2.cvtColor(s, cv2.COLOR_BGR2RGB))\n",
    "    a.axis('off')\n",
    "    \n",
    "fig.set_size_inches(10, 5 * len(stopsigns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Choose 4 images from the above dataset and plot each separate color channel in RGB, HSV, and LAB\n",
    "\n",
    "Coordinate with your teammates so that each team member chooses 4 different images. (e.g., person A chooses [0:3], person B chooses [4:7], or you can shuffle the order).\n",
    "\n",
    "Together, your team will be processing 20 images from the above dataset. For the rest of this lab, you will be working independently on your 4 images, and you will compare your answers at the end of all the exercises.\n",
    "\n",
    "Once you have selected your four images, revisit your answer in exercise 1. Is it the same for the other 4 images in your dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "# Your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "Filter the H (*Hue*) channel of the first image. Find the range of blue values that include as much of the sky as possible.\n",
    "\n",
    "Use http://colorizer.org/ to find the values in Hue that correspond to blue.\n",
    "\n",
    "However, note that OpenCV does not allow Hue to extend all the way up to 360 degrees. Why?\n",
    "\n",
    "See this answer: https://stackoverflow.com/questions/16685707/why-is-the-range-of-hue-0-180-in-opencv\n",
    "\n",
    "An 8-bit value can only hold values from 0 to 255.\n",
    "\n",
    "Therefore, in OpenCV, Hue values are between 0 and 180 (the values from colorizer are divided by 2)\n",
    "\n",
    "To filter, use the `cv2.inRange` function. See the following tutorial:\n",
    "\n",
    "https://docs.opencv.org/3.4.1/df/d9d/tutorial_py_colorspaces.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "# your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "Can you find a good range of hue values that mask out the stop sign in the four images you chose in Exercise 2?\n",
    "\n",
    "Two hints: \n",
    "\n",
    "1. Consider how polar coordinates work. Because hues are measured in angles, hue values from 0 to 5 degrees are very close to the values 355-360 (which are then divided by 2, if you are using OpenCV)\n",
    "2. You might find that saturation and value also impact the hue for stop signs. Why? One example may be shadows. Can you name others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "# your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bounding boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding bounding box rectangles to images:\n",
    "\n",
    "https://stackoverflow.com/a/37437395"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot an image on both the left and right\n",
    "fig,ax = plt.subplots(ncols=2)\n",
    "fig.set_size_inches(15,10)\n",
    "ax[0].imshow(cv2.cvtColor(stopsigns[0], cv2.COLOR_BGR2RGB));\n",
    "ax[1].imshow(cv2.cvtColor(stopsigns[0], cv2.COLOR_BGR2RGB));\n",
    "\n",
    "# Define a bounding box:\n",
    "bbox = Rectangle(xy=(300,90), width=200, height=180, linewidth=4, edgecolor='lime', facecolor='none')\n",
    "\n",
    "# add the bounding box to the image on the right\n",
    "ax[1].add_patch(bbox);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "\n",
    "Choose a different image from your dataset. Manually define a bounding box around the stop sign in that image, using `Rectangle`.\n",
    "\n",
    "What direction is positive X in? What direction is positive y in? Hint: think back to the Linear Regression exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "# your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Combining masking and morphology\n",
    "\n",
    "For the four images you selected in Exercise 2, choose a colorspace and channel that you believe will work best for isolating stop signs.\n",
    "\n",
    "1. Mask the five images using a narrow range of values in that channel.\n",
    "2. Run erosion and dilation on the mask to reduce the amount of noise. What kernel sizes work best? If you want to run erosion immediately followed by dilation for the same kernel size, you can use `opening`:\n",
    "\n",
    "https://docs.opencv.org/3.4.1/d9/d61/tutorial_py_morphological_ops.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "# your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7 - Compare with your team mates\n",
    "Some images will have a lot of \"noise\" - in other words, for any choice of color channel, and any two values for `inRange` which mask stop sign pixels, a lot of pixels which don't come from the stop sign will also be included by the filter. What causes this? Which images are most prone to noise? What's significantly different about those images compared to the others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "# team solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When you are done:\n",
    "\n",
    "\n",
    "1. Double-check that you filled in your name at the top of the notebook!\n",
    "2. Click `File` -> `Export Notebook As` -> `PDF`\n",
    "3. Email the PDF to `YOURTEAMNAME@beaver.works` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretch Goal: Combining Linear Regression and Color Segmentation\n",
    "\n",
    "A lot of the above images have solid white lines or solid yellow lines, due to traffic lane markings. A lot of the images also have solid black lines (telephone poles), and solid green lines (the pole of the stop sign).\n",
    "\n",
    "1. Choose some images that contain lines (at least 5). \n",
    "2. For each image, find a good color threshold which can mask the line or lines out.\n",
    "3. Add in erosion, dilation, opening, or other morphological operations to improve the quality of the mask.\n",
    "4. For each image, use OpenCV's linear regression function `cv2.fitLine` to plot the line of best fit from your results in the previous step.\n",
    "\n",
    "See the following tutorial for `cv2.fitLine`: https://docs.opencv.org/3.4.1/dd/d49/tutorial_py_contour_features.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
